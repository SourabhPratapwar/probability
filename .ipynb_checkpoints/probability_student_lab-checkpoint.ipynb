{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Essentials — FAANG-Level Lab\n",
    "\n",
    "**Goal:** ML-relevant probability: expectation, variance, Bayes, and simulation checks.\n",
    "\n",
    "**Outcome:** You can reason about uncertainty, distributions, and Bayes updates (interview-ready).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check(name: str, cond: bool):\n",
    "    if not cond:\n",
    "        raise AssertionError(f'Failed: {name}')\n",
    "    print(f'OK: {name}')\n",
    "\n",
    "rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 — Discrete Random Variables\n",
    "\n",
    "### Task 1.1: Expectation & variance from a PMF\n",
    "Given values x and probabilities p (sum to 1):\n",
    "- implement E[X] and Var(X)\n",
    "\n",
    "# HINT:\n",
    "- E[X] = sum p_i x_i\n",
    "- Var(X) = E[X^2] - (E[X])^2\n",
    "\n",
    "**Explain:** Why is variance not linear, but expectation is?\n",
    "\n",
    "**Answer:** Expectation is linear because it is just a weighted sum: adding random variables or scaling them simply adds or scales their averages, regardless of whether the variables are independent. Variance, however, depends on squared deviations from the mean, which introduces interaction terms when random variables are added. As a result, variance includes cross terms (covariances) and squares, so it does not distribute over addition in the same way expectation does, making variance non-linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E[X]= 1.1 Var= 0.48999999999999977\n",
      "OK: mu\n",
      "OK: var\n"
     ]
    }
   ],
   "source": [
    "def expectation(x, p):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    return float(np.sum(p * x))\n",
    "\n",
    "def variance(x, p):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    ex = np.sum(p * x)\n",
    "    ex2 = np.sum(p * x * x)\n",
    "    return float(ex2 - ex*ex)\n",
    "\n",
    "x = np.array([0, 1, 2])\n",
    "p = np.array([0.2, 0.5, 0.3])\n",
    "mu = expectation(x, p)\n",
    "var = variance(x, p)\n",
    "print('E[X]=', mu, 'Var=', var)\n",
    "check('mu', abs(mu - 1.1) < 1e-9)\n",
    "check('var', abs(var - (0.2*0 + 0.5*1 + 0.3*4 - 1.1**2)) < 1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 — Conditional Probability & Bayes\n",
    "\n",
    "### Task 2.1: Bayes theorem (classic interview)\n",
    "Disease test example:\n",
    "- prevalence P(D)=0.01\n",
    "- sensitivity P(+|D)=0.99\n",
    "- false positive rate P(+|~D)=0.05\n",
    "Compute P(D|+)\n",
    "\n",
    "# HINT:\n",
    "P(D|+) = P(+|D)P(D) / (P(+|D)P(D) + P(+|~D)P(~D))\n",
    "\n",
    "**FAANG gotcha:** base-rate fallacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(D|+)= 0.16666666666666669\n",
      "OK: range\n",
      "OK: approx\n"
     ]
    }
   ],
   "source": [
    "P_D = 0.01\n",
    "P_pos_given_D = 0.99\n",
    "P_pos_given_notD = 0.05\n",
    "\n",
    "# TODO\n",
    "P_notD = 1 - P_D\n",
    "P_pos = P_pos_given_D*P_D + P_pos_given_notD*P_notD\n",
    "P_D_given_pos = (P_pos_given_D*P_D) / P_pos\n",
    "print('P(D|+)=', P_D_given_pos)\n",
    "check('range', 0 <= P_D_given_pos <= 1)\n",
    "# Should be around 0.166...\n",
    "check('approx', abs(P_D_given_pos - (0.99*0.01)/(0.99*0.01 + 0.05*0.99)) < 1e-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Simulation check (sanity)\n",
    "Simulate N people and estimate P(D|+) empirically.\n",
    "\n",
    "# HINT:\n",
    "- sample disease ~ Bernoulli(P_D)\n",
    "- sample test result conditional on disease\n",
    "\n",
    "**Explain:** Why does simulation converge to the analytic value?\n",
    "\n",
    "**Answer:** Simulation converges to the analytic value because each simulated person is an independent draw from the same underlying probability model, so the empirical frequencies you compute (like the fraction with disease among those who test positive) are sample averages of random outcomes. By the Law of Large Numbers, as (N) grows, these sample averages concentrate around their true expected probabilities, meaning the observed conditional proportion P(D|+) approaches the exact value implied by the model (i.e., Bayes’ rule)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate 0.17002444575571105\n",
      "OK: close\n"
     ]
    }
   ],
   "source": [
    "N = 200000\n",
    "# TODO\n",
    "disease = rng.random(N) < P_D\n",
    "test_pos = np.empty(N, dtype=bool)\n",
    "test_pos[disease] = rng.random(disease.sum()) < P_pos_given_D\n",
    "test_pos[~disease] = rng.random((~disease).sum()) < P_pos_given_notD\n",
    "\n",
    "# estimate P(D|+)\n",
    "est = disease[test_pos].mean()\n",
    "print('estimate', est)\n",
    "check('close', abs(est - P_D_given_pos) < 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 — Continuous Distributions (Normal)\n",
    "\n",
    "### Task 3.1: Standardization (z-score)\n",
    "Given X ~ Normal(mu, sigma^2). Compute standardized Z=(X-mu)/sigma.\n",
    "\n",
    "# HINT:\n",
    "- simulate X and check Z mean ~0, std ~1\n",
    "\n",
    "**ML link:** standardization shows up in preprocessing and SGD stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z mean 0.00263367611867299 Z std 0.9997503191012033\n",
      "OK: mean0\n",
      "OK: std1\n"
     ]
    }
   ],
   "source": [
    "mu, sigma = 5.0, 2.0\n",
    "X = rng.normal(mu, sigma, size=200000)\n",
    "\n",
    "Z = Z = (X - mu) / sigma\n",
    "print('Z mean', Z.mean(), 'Z std', Z.std())\n",
    "check('mean0', abs(Z.mean()) < 0.02)\n",
    "check('std1', abs(Z.std() - 1.0) < 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 — Naive Bayes Thinking (Optional Mini)\n",
    "\n",
    "### Task 4.1: Compute log-odds for a toy Naive Bayes\n",
    "Given word likelihoods for spam vs ham, compute posterior odds for a message.\n",
    "\n",
    "# HINT:\n",
    "- work in log space (sum logs)\n",
    "\n",
    "**FAANG gotcha:** multiplying small probabilities underflows; use logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_ratio 6.214608098422191\n",
      "OK: finite\n"
     ]
    }
   ],
   "source": [
    "# Toy params\n",
    "prior_spam = 0.2\n",
    "prior_ham = 0.8\n",
    "P_word_given_spam = {'free': 0.08, 'win': 0.05, 'meeting': 0.001}\n",
    "P_word_given_ham  = {'free': 0.002, 'win': 0.001, 'meeting': 0.03}\n",
    "message = ['free', 'win']\n",
    "\n",
    "# TODO: compute log posterior ratio log P(spam|msg) - log P(ham|msg) up to constant\n",
    "log_ratio = np.log(prior_spam) - np.log(prior_ham)\n",
    "for w in message:\n",
    "    log_ratio += np.log(P_word_given_spam[w]) - np.log(P_word_given_ham[w])\n",
    "print('log_ratio', log_ratio)\n",
    "check('finite', np.isfinite(log_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Submission Checklist\n",
    "- All TODOs completed\n",
    "- Checks pass\n",
    "- Explain prompts answered\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
